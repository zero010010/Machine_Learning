{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perceptron\n",
    "\n",
    "<img src=\"./img/perceptron-6168423.jpg\" alt=\"drawing\" width=\"650\"/>\n",
    "\n",
    "\n",
    "Perceptrons are a type of artificial neural network that are **used primarily for binary classification.** Some key uses and applications of perceptrons include:\n",
    "\n",
    "**Linear binary classification:** Perceptrons can classify data that is linearly separable into two classes (0 or 1, yes or no, etc). The output is based on a linear prediction function.\n",
    "\n",
    "**Pattern recognition:** Perceptrons can be trained to recognize simple patterns in data. For example, scanning images to recognize shapes or characters.\n",
    "\n",
    "**Function approximation:** Perceptrons can approximate simple functions to map inputs to outputs. For example, modeling relationships between variables.\n",
    "\n",
    "**Logical operators:** Perceptrons can be configured to model logical operators like AND, OR, NOT. Useful for implementing simple logic circuits.\n",
    "\n",
    "**Single layer neural networks**: Single perceptrons are limited, but networks of perceptrons in a single layer can model more complex functions.\n",
    "\n",
    "**Activation function:** The perceptron algorithm applies an activation function like a step function to the weighted sum of inputs to generate an output.\n",
    "\n",
    "Perceptron excel at **basic linear classification and pattern recognition tasks, but are limited in their capabilities compared to multilayer neural networks**. Their simple linear structure makes them easy to understand and implement.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos datos. Utilizaremos el dataset de pinguinos de seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl #ignore ssl certificate errors\n",
    "ssl._create_default_https_context = ssl._create_unverified_context  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and display the first 5 rows of the penguins dataset.\n",
    "\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>island_Biscoe</th>\n",
       "      <th>island_Dream</th>\n",
       "      <th>island_Torgersen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0        0            39.1           18.7              181.0       3750.0   \n",
       "1        0            39.5           17.4              186.0       3800.0   \n",
       "2        0            40.3           18.0              195.0       3250.0   \n",
       "4        0            36.7           19.3              193.0       3450.0   \n",
       "5        0            39.3           20.6              190.0       3650.0   \n",
       "\n",
       "   sex  island_Biscoe  island_Dream  island_Torgersen  \n",
       "0    0              0             0                 1  \n",
       "1    1              0             0                 1  \n",
       "2    1              0             0                 1  \n",
       "4    1              0             0                 1  \n",
       "5    0              0             0                 1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"penguins\")# Load the penguins dataset from seaborn\n",
    "\n",
    "# Feauture engineering \n",
    " \n",
    "# Remove any rows that contain missing values.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Dictionary maps each categorical value to a numeric code.\n",
    "#  Replacing the values encodes the categories as numbers\n",
    "cleanup_nums = {\"species\": {\"Adelie\": 0,\n",
    "                            \"Chinstrap\": 1,\n",
    "                            \"Gentoo\": 2},\n",
    "               \"sex\": {\"Male\": 0,\n",
    "                       \"Female\": 1}}\n",
    "df.replace(cleanup_nums, inplace=True)# replace the values in the dictionary with the values in the dictionary\n",
    "\n",
    "'''creates one-hot encoded columns for each possible category. \n",
    "This converts each categorical variable into \n",
    "multiple binary columns \n",
    "that can be used as inputs.'''\n",
    "\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 333 entries, 0 to 343\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            333 non-null    int64  \n",
      " 1   bill_length_mm     333 non-null    float64\n",
      " 2   bill_depth_mm      333 non-null    float64\n",
      " 3   flipper_length_mm  333 non-null    float64\n",
      " 4   body_mass_g        333 non-null    float64\n",
      " 5   sex                333 non-null    int64  \n",
      " 6   island_Biscoe      333 non-null    uint8  \n",
      " 7   island_Dream       333 non-null    uint8  \n",
      " 8   island_Torgersen   333 non-null    uint8  \n",
      "dtypes: float64(4), int64(2), uint8(3)\n",
      "memory usage: 19.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>island_Biscoe</th>\n",
       "      <th>island_Dream</th>\n",
       "      <th>island_Torgersen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.918919</td>\n",
       "      <td>43.992793</td>\n",
       "      <td>17.164865</td>\n",
       "      <td>200.966967</td>\n",
       "      <td>4207.057057</td>\n",
       "      <td>0.495495</td>\n",
       "      <td>0.489489</td>\n",
       "      <td>0.369369</td>\n",
       "      <td>0.141141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.889718</td>\n",
       "      <td>5.468668</td>\n",
       "      <td>1.969235</td>\n",
       "      <td>14.015765</td>\n",
       "      <td>805.215802</td>\n",
       "      <td>0.500732</td>\n",
       "      <td>0.500642</td>\n",
       "      <td>0.483360</td>\n",
       "      <td>0.348691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.100000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>3550.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>4050.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.600000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>4775.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>59.600000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>6300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          species  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "count  333.000000      333.000000     333.000000         333.000000   \n",
       "mean     0.918919       43.992793      17.164865         200.966967   \n",
       "std      0.889718        5.468668       1.969235          14.015765   \n",
       "min      0.000000       32.100000      13.100000         172.000000   \n",
       "25%      0.000000       39.500000      15.600000         190.000000   \n",
       "50%      1.000000       44.500000      17.300000         197.000000   \n",
       "75%      2.000000       48.600000      18.700000         213.000000   \n",
       "max      2.000000       59.600000      21.500000         231.000000   \n",
       "\n",
       "       body_mass_g         sex  island_Biscoe  island_Dream  island_Torgersen  \n",
       "count   333.000000  333.000000     333.000000    333.000000        333.000000  \n",
       "mean   4207.057057    0.495495       0.489489      0.369369          0.141141  \n",
       "std     805.215802    0.500732       0.500642      0.483360          0.348691  \n",
       "min    2700.000000    0.000000       0.000000      0.000000          0.000000  \n",
       "25%    3550.000000    0.000000       0.000000      0.000000          0.000000  \n",
       "50%    4050.000000    0.000000       0.000000      0.000000          0.000000  \n",
       "75%    4775.000000    1.000000       1.000000      1.000000          0.000000  \n",
       "max    6300.000000    1.000000       1.000000      1.000000          1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 333 total samples, which is a decent amount of data to train a model.\n",
    "\n",
    "* The **'species' column shows the samples are not evenly distributed between the 3 classes** (Adelie, Chinstrap, Gentoo), with Adelie being the most common. This class imbalance is something we'll need to consider when training and evaluating models.\n",
    "\n",
    "* **The mean 'bill_length_mm' and 'bill_depth_mm' vary quite a bit between the min and max values, suggesting these features may be useful for distinguishing between penguin species.**\n",
    "\n",
    "* **'flipper_length_mm' could also be a useful distinguishing feature based on its range of values.**\n",
    "\n",
    "* There is a large range in 'body_mass_g' **but the standard deviation is also high, so this may not be as useful of a feature.**\n",
    "\n",
    "* The 'sex' column is evenly split between 0 and 1, so no class imbalance problem there.\n",
    "\n",
    "* *Only some samples are from the 'island_Biscoe' and very few from 'island_Torgersen', so island data may not be that useful.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos en train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train / Test\n",
    "\n",
    "X = df.iloc[:, 1:]#X = df.drop('species', axis=1) \n",
    "y = df.iloc[:, 0]#y = df['species']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    146\n",
       "2    119\n",
       "1     68\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()# count the number of occurrences of each value(spicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 8)\n",
      "(67, 8)\n",
      "(266,)\n",
      "(67,)\n"
     ]
    }
   ],
   "source": [
    "# Validating the shapes verifies the training and test sets\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar un Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19402985074626866"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\"\"\"\n",
    "Perceptron classifier model from scikit-learn.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Fits a Perceptron classifier model on the training data, \n",
    "scores it on the test data, and returns the accuracy score.\n",
    "\n",
    "Parameters:\n",
    "X_train (array-like): Training data\n",
    "y_train (array-like): Training labels\n",
    "X_test (array-like): Test data\n",
    "y_test (array-like): Test labels  \n",
    "\n",
    "Returns:\n",
    "Accuracy score of the model on the test data\n",
    "\"\"\"\n",
    "\n",
    "per_clf = Perceptron(random_state=1) # reduce variance =1, considered good practice\n",
    "per_clf.fit(X_train, y_train)\n",
    "per_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score 0.19402985074626866**\n",
    "\n",
    "* Percentage of test samples that were classified correctly by the model. It is computed as:\n",
    "\n",
    "* **Accuracy** = Number of correct predictions / Total number of predictions\n",
    "\n",
    "* So in this case, with an accuracy score of 0.19402985074626866, it means the model made **correct predictions on 19.40% of the test set samples.**\n",
    "\n",
    "* This suggests it is not very effective at classifying the penguin species in this dataset and has substantial room for improvement.\n",
    "\n",
    "* Some key things to note about accuracy as an evaluation metric:\n",
    "\n",
    "* Higher is better, with 1.0 meaning 100% correct classification\n",
    "* It can be misleading for imbalanced datasets - precision/recall may be more informative\n",
    "* It only measures raw prediction correctness, not model confidence\n",
    "* Useful for baseline model performance, but other metrics also important\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850746268656716"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic regression model\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "#  Score\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The logistic regression model is performing very well, with an accuracy of 98% on the test data. This is a significant improvement over the previous perceptron model.\n",
    "\n",
    "* A score of 0.98 indicates the model is **correctly classifying almost all of the penguin samples in the test set across the 3 species classes.**\n",
    "\n",
    "* The high accuracy suggests logistic regression is much better suited for this multi-class classification task compared to the binary perceptron model.\n",
    "\n",
    "* Logistic regression is likely **able to capture non-linear relationships between the input features and species outputs.** This results in higher precision.\n",
    "\n",
    "* **The regularization used in logistic regression is preventing overfitting**, allowing accurate generalization to the test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos a estandarizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que el perceptrón por si solo es bastante inútil, habrá que probar configuraciones más complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43283582089552236"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test accuracy reported for the Multilayer Perceptron model on this dataset is 0.43283582089552236.**\n",
    "\n",
    "\n",
    "\n",
    "* The MLP is still outperforming the original single perceptron, but only slightly at 43% vs 19% accuracy.\n",
    "\n",
    "* It is not able to effectively model the relationships between the input features and species outputs beyond what a linear model can do.\n",
    "\n",
    "* There are likely challenges in properly tuning and optimizing a neural network model on this small, relatively simple dataset.\n",
    "\n",
    "* Overfitting is probably still an issue, leading to poorer generalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos otra configuración. Es posible crear una red neuronal desde la propia función de MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34328358208955223"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=500,\n",
    "                   activation='tanh',\n",
    "                   hidden_layer_sizes = (150, 150, 150),\n",
    "                   random_state=42)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The changes to the MLP (more layers, tanh activation, more iterations) did not lead to significant improvement in test performance.\n",
    "\n",
    "The accuracy is still only around 34%, similar to the original MLP model.\n",
    "\n",
    "It seems the increased depth and non-linearity has not helped the model generalize better to the test data.\n",
    "\n",
    "The additional complexity may have made overfitting worse, even with the same training/test split.\n",
    "\n",
    "This dataset and problem may be too small and simple for a deep neural network to provide benefit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizan descenso del gradiente, y por tanto son muy sensibles al escalado. Estandarizamos para el siguiente ejemplo\n",
    "\n",
    "**Standardization** put all features on the same scale, allowing the Perceptron to weigh them appropriately.\n",
    "\n",
    "It likely **helped the model converge much faster during training without certain features dominating.**\n",
    "\n",
    "**Overfitting was probably reduced** since feature scales were no longer skewed.\n",
    "\n",
    "*The test accuracy of 1.0 shows excellent generalization ability despite perfect training accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_s = sc.transform(X_train)\n",
    "X_test_s = sc.transform(X_test)\n",
    "\n",
    "# Evaluate perceptron after scaling\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X_train_s, y_train)\n",
    "print(per_clf.score(X_train_s, y_train))\n",
    "print(per_clf.score(X_test_s, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize the input features before training a Perceptron model.** Standardization can improve model performance in several ways:\n",
    "\n",
    "* It centers the data to have a mean of 0 and scales it to have a unit standard deviation. This puts all features on the same scale.\n",
    "\n",
    "* It helps the model converge faster during training. Features on different scales can slow learning.\n",
    "\n",
    "* It prevents features with larger ranges dominating those with smaller ranges.\n",
    "\n",
    "* It may reduce overfitting on training data.\n",
    "\n",
    "\n",
    "**Fits StandardScaler()** to the training data and uses it to transform both train and test sets.\n",
    "\n",
    "* Trains a Perceptron model on the scaled training data.\n",
    "\n",
    "* Evaluates on scaled test data.\n",
    "\n",
    "* **Right approach** -  scale using statistics calculated only on the training set, then apply the same scaling to test data.\n",
    "\n",
    "* Evaluating the model on scaled data will give you a more accurate sense of its real-world performance. The scaling step is simple to implement and can often noticeably improve results.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Log Regress after scaler applied\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_s, y_train)\n",
    "\n",
    "\n",
    "print(log_reg.score(X_train_s, y_train))\n",
    "print(log_reg.score(X_test_s, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scal =scaler.transform(X_train)\n",
    "X_test_scal =scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(max_iter=500)\n",
    "mlp.fit(X_train_scal, y_train)\n",
    "print(mlp.score(X_train_scal, y_train))\n",
    "print(mlp.score(X_test_scal, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**re-evaluate the Multilayer Perceptron (MLP) model:**\n",
    "\n",
    "**MLPs can be sensitive to feature scales**: Like many machine learning models, MLPs perform best when all features are on a similar scale. Standardization helps address this.\n",
    "\n",
    "**Avoid large feature dominance**: Scaling prevents features with large original ranges from dominating the MLP model training.\n",
    "\n",
    "**Faster convergence**: Standardized features can help the MLP converge much faster during training.\n",
    "\n",
    "**Reduced overfitting**: Scaling can reduce overfitting on training data, improving generalization.\n",
    "\n",
    "**Fair evaluation**: Comparing MLP performance on standardized data to the other models (like logistic regression) is a more fair and direct comparison.\n",
    "\n",
    "**Best practice**: Preprocessing data and re-evaluating models is considered a good machine learning practice to quantify impact.\n",
    "\n",
    "**Confirm previous results**: We can verify whether standardization helps improve the MLP model on this dataset, compared to previous results without scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31,  0,  0],\n",
       "       [ 0, 13,  0],\n",
       "       [ 0,  0, 23]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Visualizing the performance of the classification model\n",
    "\n",
    "confusion_matrix(y_test, mlp.predict(X_test_scal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagonal entries show the number of correct predictions for each class, while the off-diagonal entries show the errors between classes.\n",
    "\n",
    "\n",
    "**Class 1** had 31 correct predictions, 0 incorrect predictions as class 2, and 0 incorrect as class 3<br>\n",
    "**Class 2** had 0 incorrect predictions as class 1, 13 correct predictions, and 0 incorrect as class 3<br>\n",
    "**Class 3** had 0 incorrect predictions as class 1, 0 incorrect as class 2, and 23 correct predictions<br>\n",
    "\n",
    "* Relatively good performance, with most predictions along the diagonal and minimal confusion between the different classes. The total number of examples for each class can be seen by summing the rows or columns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
