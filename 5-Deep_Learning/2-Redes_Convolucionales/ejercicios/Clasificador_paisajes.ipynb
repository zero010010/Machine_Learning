{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador paisajes\n",
    "Para este ejercicio vas a crear un clasificador automático de paisajes. Los datos los encontrarás en el Classroom como `seg_train.zip` y `seg_test.zip`. Se pide:\n",
    "1. Cargar las imágenes. Mira cómo están almacenados los datos. Tendrás que recorrer las carpetas, cargar las imágenes en memoria y etiquetarlas con los nombres de las carpetas. Realiza un reshape de cada imagen (comienza el ejercicio con 32x32, para ir más rápido en las ejecuciones).\n",
    "2. Investiga las imágenes, comprueba con algunas muestras que has cargado bien los datos.\n",
    "3. Normaliza\n",
    "4. Diseña la arquitectura de la red. Recuerda que es un algiritmo de clasificación. Ojo con las dimensiones de la entrada\n",
    "5. Reserva un 20% de los datos del entrenamiento para validar.\n",
    "6. Representa el objeto history\n",
    "7. Evalua el modelo con los datos de test\n",
    "8. Representa algunos de los paisajes donde el modelo comete errores\n",
    "9. Crea una matriz de confusión con los errores del modelo\n",
    "\n",
    "**NOTA apartado 1**: para el apartado 1 tendras que recorre las carpetas/imagenes con `os.listdir()`, e ir cargando todas las imagenes como arrays de numpy\n",
    "\n",
    "**NOTA apartado 4**: empieza con un par de capas Conv2D + MaxPooling2D con activación relu y después la fully connected layer. on softmax como ultima capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 18:34:23.073810: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['mountain','street','glacier', 'buildings','sea','forest']\n",
    "\n",
    "IMAGE_SIZE = (32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mountain': 0,\n",
       " 'street': 1,\n",
       " 'glacier': 2,\n",
       " 'buildings': 3,\n",
       " 'sea': 4,\n",
       " 'forest': 5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names_label = {class_name:i for i ,class_name in enumerate(class_names)}\n",
    "class_names_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"/Users/miguelopez/Desktop/Machine Learning_2/5-Deep_Learning/2-Redes_Convolucionales/paisajes/seg_train\"\n",
    "TEST_PATH = \"/Users/miguelopez/Desktop/Machine Learning_2/5-Deep_Learning/2-Redes_Convolucionales/paisajes/seg_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, im_size, class_names_label):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for folder in os.listdir(path):\n",
    "        label = class_names_label[folder]\n",
    "        folder_path = os.path.join(path,folder)\n",
    "        # Iterar sobre todo lo que haya en path\n",
    "        for file in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path,file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, im_size)\n",
    "            X.append(image)\n",
    "            y.append(label)\n",
    "    \n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'.DS_Store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m read_data(TRAIN_PATH, IMAGE_SIZE, class_names_label)\n\u001b[1;32m      2\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m read_data(TEST_PATH, IMAGE_SIZE, class_names_label)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mread_data\u001b[0;34m(path, im_size, class_names_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(path):\n\u001b[0;32m----> 6\u001b[0m     label \u001b[38;5;241m=\u001b[39m class_names_label[folder]\n\u001b[1;32m      7\u001b[0m     folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path,folder)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Iterar sobre todo lo que haya en path\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: '.DS_Store'"
     ]
    }
   ],
   "source": [
    "X_train, y_train = read_data(TRAIN_PATH, IMAGE_SIZE, class_names_label)\n",
    "X_test, y_test = read_data(TEST_PATH, IMAGE_SIZE, class_names_label)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for folder in os.listdir(TRAIN_PATH):\n",
    "#     if folder == '.DS_Store':\n",
    "#         continue\n",
    "        \n",
    "#     label = class_names_label[folder]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c77fdb427e7cbc9bc1367dd530fc2b36aacdbbde1ac83c85833b10dfa8b831c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
