{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch & Pipelines\n",
    "GridSearch is an optimization tool that we use when tuning hyperparameters. We define the grid of parameters that we want to search through, and we select the best combination of parameters for our data.\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 1\n",
    "Itera un algoritmo sobre un conjunto de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26880"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "168 * 8 * 2 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "clf.best_stimator_ SVC(C=10, coef0=1, degree=2, kernel='poly')\n",
      "clf.best_params_ {'C': 10, 'coef0': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "clf.best_score 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 'kernel':('linear', 'poly', 'rbf', 'sigmoid'), \n",
    "\n",
    "parameters = {\n",
    "    'kernel':('linear', 'rbf', 'poly'), \n",
    "    'C':[10, 100], \n",
    "    'degree': [2,3],\n",
    "    'coef0': [-1., 1],\n",
    "    'gamma': ('scale', 'auto')\n",
    "    }\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "clf = GridSearchCV(estimator=svc,\n",
    "                   param_grid=parameters,\n",
    "                   n_jobs=-1, # All kernels in computer\n",
    "                   cv=10,\n",
    "                   verbose=.5) # Folds in cross validation\n",
    "\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "print(\"clf.best_stimator_\", clf.best_estimator_)\n",
    "print(\"clf.best_params_\", clf.best_params_)\n",
    "\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"clf.best_score\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_res = pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.sort_values(by='rank_test_score').to_csv('cv_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 2\n",
    "\n",
    "La forma pro es la que hace esto mismo y va recogiendo los errores de entrenamiento, de validación y tiene la capacidad de parar el proceso cuando se requiera además de guardar el modelo en local una vez terminado si es mejor que el que había anteriormente y de cargar el modelo anterior y seguir reentrenando.\n",
    "\n",
    "Para montar un único gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test = np.arange(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "# Le podemos poner cualquier clasificador. Irá cambiando según va probando pero necesita 1.\n",
    "pipe = Pipeline(steps=[('imputer', SimpleImputer()),('classifier', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "logistic_params = {\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__C': np.logspace(0, 4, 10),\n",
    "    'imputer__strategy': ['mean', 'median', 'most_frequent']\n",
    "    }\n",
    "\n",
    "random_forest_params = {\n",
    "    'classifier': [RandomForestClassifier()],\n",
    "    'classifier__n_estimators': [10, 100, 1000],\n",
    "    'classifier__max_features': [1, 2, 3],\n",
    "    'imputer__strategy': ['mean', 'median', 'most_frequent']\n",
    "    }\n",
    "\n",
    "svm_params = {\n",
    "    'classifier': [svm.SVC()],\n",
    "    'classifier__kernel':('linear', 'rbf', 'sigmoid'), \n",
    "    'classifier__C':[0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "    'classifier__degree': to_test,\n",
    "    'classifier__coef0': [-10.,-1., 0., 0.1, 0.5, 1, 10, 100],\n",
    "    'classifier__gamma': ('scale', 'auto'),\n",
    "    'imputer__strategy': ['mean', 'median', 'most_frequent']\n",
    "    }\n",
    "\n",
    "\n",
    "# Create space of candidate learning algorithms and their hyperparameters\n",
    "search_space = [\n",
    "    logistic_params,\n",
    "    random_forest_params,\n",
    "    svm_params\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 52275.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "\n",
      "best estimator: LogisticRegression(C=2.7825594022071245)\n",
      "\n",
      "############################\n",
      "\n",
      "clf.best_params_ {'classifier': LogisticRegression(C=2.7825594022071245), 'classifier__C': 2.7825594022071245, 'classifier__penalty': 'l2', 'imputer__strategy': 'mean'}\n",
      "\n",
      "############################\n",
      "\n",
      "clf.best_score 0.975\n",
      "CPU times: total: 37.9 s\n",
      "Wall time: 3min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.33333333 0.33333333 0.33333333]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Repeats the CV n times\n",
    "# cv = RepeatedKFold(n_splits=10, n_repeats=2, random_state=1)\n",
    "\n",
    "\n",
    "# Create grid search \n",
    "clf = GridSearchCV(estimator=pipe,\n",
    "                   param_grid=search_space,\n",
    "                   cv=5,\n",
    "                   verbose=0,\n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "# View best model\n",
    "separator = \"\\n############################\\n\"\n",
    "print(separator)\n",
    "print(\"best estimator:\", best_model.best_estimator_.get_params()['classifier'])\n",
    "print(separator)\n",
    "print(\"clf.best_params_\", clf.best_params_)\n",
    "print(separator)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"clf.best_score\", clf.best_score_)\n",
    "#SAVE MODEL\n",
    "# save the model to disk\n",
    "filename = 'finished_model.sav'\n",
    "#pickle.dump(best_model, open(filename, 'wb'))\n",
    "\n",
    "with open('finished_model.model', \"wb\") as archivo_salida:\n",
    "    pickle.dump(best_model.best_estimator_, archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__penalty</th>\n",
       "      <th>param_imputer__strategy</th>\n",
       "      <th>param_classifier__max_features</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__coef0</th>\n",
       "      <th>param_classifier__degree</th>\n",
       "      <th>param_classifier__gamma</th>\n",
       "      <th>param_classifier__kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5227</th>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>median</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'classifier': SVC(), 'classifier__C': 0.5, 'c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4326</th>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'classifier': SVC(), 'classifier__C': 0.5, 'c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'classifier': SVC(), 'classifier__C': 0.5, 'c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>median</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'classifier': SVC(), 'classifier__C': 0.5, 'c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'classifier': SVC(), 'classifier__C': 0.5, 'c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=2.7825594022071245)</td>\n",
       "      <td>3593.813664</td>\n",
       "      <td>l1</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=2.78255940...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=2.7825594022071245)</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>median</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=2.78255940...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.038667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=2.7825594022071245)</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=2.78255940...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=2.7825594022071245)</td>\n",
       "      <td>166.810054</td>\n",
       "      <td>l1</td>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=2.78255940...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.416378</td>\n",
       "      <td>0.122680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=2.7825594022071245)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier': LogisticRegression(C=2.78255940...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10455 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5227       0.002589      0.001720         0.001204        0.000509   \n",
       "4326       0.002755      0.001210         0.001152        0.001316   \n",
       "4319       0.002609      0.001136         0.000602        0.000492   \n",
       "4318       0.002445      0.000891         0.000601        0.000491   \n",
       "4317       0.001643      0.000490         0.000710        0.000406   \n",
       "...             ...           ...              ...             ...   \n",
       "50         0.001603      0.000490         0.000000        0.000000   \n",
       "55         0.001201      0.000401         0.000000        0.000000   \n",
       "56         0.021099      0.038667         0.000000        0.000000   \n",
       "30         0.001603      0.000374         0.000000        0.000000   \n",
       "0          5.416378      0.122680         0.000000        0.000000   \n",
       "\n",
       "                              param_classifier param_classifier__C  \\\n",
       "5227                                     SVC()                 0.5   \n",
       "4326                                     SVC()                 0.5   \n",
       "4319                                     SVC()                 0.5   \n",
       "4318                                     SVC()                 0.5   \n",
       "4317                                     SVC()                 0.5   \n",
       "...                                        ...                 ...   \n",
       "50    LogisticRegression(C=2.7825594022071245)         3593.813664   \n",
       "55    LogisticRegression(C=2.7825594022071245)             10000.0   \n",
       "56    LogisticRegression(C=2.7825594022071245)             10000.0   \n",
       "30    LogisticRegression(C=2.7825594022071245)          166.810054   \n",
       "0     LogisticRegression(C=2.7825594022071245)                 1.0   \n",
       "\n",
       "     param_classifier__penalty param_imputer__strategy  \\\n",
       "5227                       NaN                  median   \n",
       "4326                       NaN                    mean   \n",
       "4319                       NaN           most_frequent   \n",
       "4318                       NaN                  median   \n",
       "4317                       NaN                    mean   \n",
       "...                        ...                     ...   \n",
       "50                          l1           most_frequent   \n",
       "55                          l1                  median   \n",
       "56                          l1           most_frequent   \n",
       "30                          l1                    mean   \n",
       "0                           l1                    mean   \n",
       "\n",
       "     param_classifier__max_features param_classifier__n_estimators  \\\n",
       "5227                            NaN                            NaN   \n",
       "4326                            NaN                            NaN   \n",
       "4319                            NaN                            NaN   \n",
       "4318                            NaN                            NaN   \n",
       "4317                            NaN                            NaN   \n",
       "...                             ...                            ...   \n",
       "50                              NaN                            NaN   \n",
       "55                              NaN                            NaN   \n",
       "56                              NaN                            NaN   \n",
       "30                              NaN                            NaN   \n",
       "0                               NaN                            NaN   \n",
       "\n",
       "     param_classifier__coef0 param_classifier__degree param_classifier__gamma  \\\n",
       "5227                     100                        7                    auto   \n",
       "4326                     0.0                        2                    auto   \n",
       "4319                     0.0                        2                   scale   \n",
       "4318                     0.0                        2                   scale   \n",
       "4317                     0.0                        2                   scale   \n",
       "...                      ...                      ...                     ...   \n",
       "50                       NaN                      NaN                     NaN   \n",
       "55                       NaN                      NaN                     NaN   \n",
       "56                       NaN                      NaN                     NaN   \n",
       "30                       NaN                      NaN                     NaN   \n",
       "0                        NaN                      NaN                     NaN   \n",
       "\n",
       "     param_classifier__kernel  \\\n",
       "5227                   linear   \n",
       "4326                   linear   \n",
       "4319                   linear   \n",
       "4318                   linear   \n",
       "4317                   linear   \n",
       "...                       ...   \n",
       "50                        NaN   \n",
       "55                        NaN   \n",
       "56                        NaN   \n",
       "30                        NaN   \n",
       "0                         NaN   \n",
       "\n",
       "                                                 params  split0_test_score  \\\n",
       "5227  {'classifier': SVC(), 'classifier__C': 0.5, 'c...                1.0   \n",
       "4326  {'classifier': SVC(), 'classifier__C': 0.5, 'c...                1.0   \n",
       "4319  {'classifier': SVC(), 'classifier__C': 0.5, 'c...                1.0   \n",
       "4318  {'classifier': SVC(), 'classifier__C': 0.5, 'c...                1.0   \n",
       "4317  {'classifier': SVC(), 'classifier__C': 0.5, 'c...                1.0   \n",
       "...                                                 ...                ...   \n",
       "50    {'classifier': LogisticRegression(C=2.78255940...                NaN   \n",
       "55    {'classifier': LogisticRegression(C=2.78255940...                NaN   \n",
       "56    {'classifier': LogisticRegression(C=2.78255940...                NaN   \n",
       "30    {'classifier': LogisticRegression(C=2.78255940...                NaN   \n",
       "0     {'classifier': LogisticRegression(C=2.78255940...                NaN   \n",
       "\n",
       "      split1_test_score  split2_test_score  split3_test_score  \\\n",
       "5227                1.0                1.0           0.916667   \n",
       "4326                1.0                1.0           0.916667   \n",
       "4319                1.0                1.0           0.916667   \n",
       "4318                1.0                1.0           0.916667   \n",
       "4317                1.0                1.0           0.916667   \n",
       "...                 ...                ...                ...   \n",
       "50                  NaN                NaN                NaN   \n",
       "55                  NaN                NaN                NaN   \n",
       "56                  NaN                NaN                NaN   \n",
       "30                  NaN                NaN                NaN   \n",
       "0                   NaN                NaN                NaN   \n",
       "\n",
       "      split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "5227           0.958333            0.975        0.033333                1  \n",
       "4326           0.958333            0.975        0.033333                1  \n",
       "4319           0.958333            0.975        0.033333                1  \n",
       "4318           0.958333            0.975        0.033333                1  \n",
       "4317           0.958333            0.975        0.033333                1  \n",
       "...                 ...              ...             ...              ...  \n",
       "50                  NaN              NaN             NaN            10451  \n",
       "55                  NaN              NaN             NaN            10452  \n",
       "56                  NaN              NaN             NaN            10453  \n",
       "30                  NaN              NaN             NaN            10454  \n",
       "0                   NaN              NaN             NaN            10455  \n",
       "\n",
       "[10455 rows x 23 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res_2 = pd.DataFrame(clf.cv_results_)\n",
    "df_res_2.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('finished_model.model', \"rb\") as archivo_entrada:\n",
    "    pipeline_importada = pickle.load(archivo_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.66666666666667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict target vector\n",
    "pipeline_importada.score(X_test, y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(C=2.7825594022071245))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(C=2.7825594022071245))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=2.7825594022071245)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                ('classifier', LogisticRegression(C=2.7825594022071245))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_importada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definimos los clasificadores en sus Pipelines\n",
    "reg_log = Pipeline(steps=[\n",
    "                          (\"imputer\",SimpleImputer()),\n",
    "                          (\"scaler\",StandardScaler()),\n",
    "                          (\"reglog\",LogisticRegression())\n",
    "                         ])\n",
    "\n",
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "svm = Pipeline(steps=[(\"scaler\",StandardScaler()),\n",
    "                      (\"selectkbest\",SelectKBest()),\n",
    "                      (\"svm\",SVC())])\n",
    "\n",
    "# Definimos sus hiperparametros\n",
    "reg_log_param = {    \n",
    "                 \"imputer__strategy\": ['mean', 'median', 'most_frequent'],\n",
    "                 \"reglog__penalty\": [\"l1\",\"l2\"], \n",
    "                 \"reglog__C\": np.logspace(0, 4, 10)\n",
    "                }\n",
    "\n",
    "rand_forest_param = {\n",
    "    'n_estimators': [10, 100, 1000],\n",
    "    'max_features': [1, 2, 3]\n",
    "    }\n",
    "\n",
    "\n",
    "svm_param = {                    \n",
    "            'selectkbest__k': [1,2,3],\n",
    "            'svm__C': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "            'svm__kernel': [\"linear\",\"poly\",\"rbf\"],\n",
    "            'svm__coef0': [-10.,-1., 0., 0.1, 0.5, 1, 10, 100],\n",
    "            'svm__gamma': ('scale', 'auto')\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gs_reg_log = GridSearchCV(reg_log,\n",
    "                            reg_log_param,\n",
    "                            cv=10,\n",
    "                            scoring=\"accuracy\",\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "gs_rand_forest = GridSearchCV(rand_forest,\n",
    "                            rand_forest_param,\n",
    "                            cv=10,\n",
    "                            scoring=\"accuracy\",\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "gs_svm = GridSearchCV(svm,\n",
    "                        svm_param,\n",
    "                        cv=10,\n",
    "                        scoring=\"accuracy\",\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "grids = {\"gs_reg_log\":gs_reg_log,\n",
    "         \"gs_rand_forest\":gs_rand_forest,\n",
    "         \"gs_svm\":gs_svm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   16.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1152 candidates, totalling 11520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2160 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 6160 tasks      | elapsed:    8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 11520 out of 11520 | elapsed:   15.3s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for nombre, grid_search in grids.items():\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grid</th>\n",
       "      <th>Best score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs_reg_log</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs_rand_forest</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs_svm</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Grid  Best score\n",
       "0      gs_reg_log    0.966667\n",
       "1  gs_rand_forest    0.966667\n",
       "2          gs_svm    0.966667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grids = [(i, j.best_score_) for i, j in grids.items()]\n",
    "\n",
    "best_grids = pd.DataFrame(best_grids, columns=[\"Grid\", \"Best score\"]).sort_values(by=\"Best score\", ascending=False)\n",
    "best_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_features': [1, 2, 3],\n",
       "                         'n_estimators': [10, 100, 1000]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El mejor modelo ha sido\n",
    "best_model = grids[\"gs_rand_forest\"]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejor_modelo = best_model.best_estimator_\n",
    "mejor_modelo.fit(X_train, y_train)\n",
    "mejor_modelo.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos escogido modelo gracias a los datos de validación. Ahora habría que entrenar el modelo con TODOS los datos de train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearch\n",
    "El problema que tiene el GridSearchCV es que computacionalmente es muy costoso cuando el espacio dimensional de los hiperparámetros es grande.\n",
    "\n",
    "Mediante el RandomSearch no se prueban todas las combinaciones, sino unas cuantas de manera aleatoria. Funciona bien con datasets con pocas features. Incluso [hay papers](https://www.jmlr.org/papers/v13/bergstra12a.html) que aseguran que es más eficiente RandomSearch frente a GridSearch\n",
    "\n",
    "![imagen](https://miro.medium.com/proxy/1*ZTlQm_WRcrNqL-nLnx6GJA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daney\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 60 is smaller than n_iter=500. Running 60 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9666666666666666\n",
      "Best Hyperparameters: {'reglog__penalty': 'l2', 'reglog__C': 59.94842503189409, 'imputer__strategy': 'mean'}\n",
      "Best Estimator: Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n",
      "                ('reglog', LogisticRegression(C=59.94842503189409))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "reg_log = Pipeline(steps=[\n",
    "                          (\"imputer\",SimpleImputer()),\n",
    "                          (\"scaler\",StandardScaler()),\n",
    "                          (\"reglog\",LogisticRegression())\n",
    "                         ])\n",
    "\n",
    "reg_log_param = {    \n",
    "                 \"imputer__strategy\": ['mean', 'median', 'most_frequent'],\n",
    "                 \"reglog__penalty\": [\"l1\",\"l2\"], \n",
    "                 \"reglog__C\": np.logspace(0, 4, 10)\n",
    "                }\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(reg_log,\n",
    "                            reg_log_param,\n",
    "                            n_iter=50, # Iteraciones en los hiperparámetros\n",
    "                            scoring='accuracy',\n",
    "                            n_jobs=-1,\n",
    "                            cv=10,\n",
    "                            random_state=42)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "print('Best Estimator: %s' % result.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7600a12950a547366bb7a6732117e300ffd26224351912980486e1126c5d0f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
